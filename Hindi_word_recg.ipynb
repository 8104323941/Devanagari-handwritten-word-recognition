{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_digits\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "from statistics import mean\n",
    "from sympy import sympify\n",
    "from time import sleep\n",
    "from sympy import Symbol, sympify, factor, plot, solve, sin, Limit, Derivative, init_printing\n",
    "from sympy import Integral, log\n",
    "from collections import deque\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Images from test() functions are fed here processed,manupulated and finally predicted\n",
    "def predictions(img):\n",
    "    #Loading previously trained model\n",
    "    json_file = open('OneDrive/Desktop/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"OneDrive/Desktop/model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "    # converting image from RGB to gray scale\n",
    "    gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Removing unnecessary noise from the image by using kernel of size 5*5\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "# Adaptive thresholding of image before sending it to further manupulation\n",
    "    thresh =  cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, blockSize = 321, C = 38)\n",
    "    count=0\n",
    "    t=[]\n",
    "    # Loops overs each column element of thresh image row to find out for pixel intensity 255(white) inorder to find for a row with maximum white pixel intensity\n",
    "    #that will in turn be the header of our hindi word.\n",
    "    for i in [*range(thresh.shape[0])]:\n",
    "\n",
    "        for j in [*range(thresh.shape[1])]:\n",
    "            if thresh[i,j]==255 :\n",
    "                count+=1\n",
    "            else:\n",
    "                continue\n",
    "        #keeps count for number of element with pixel int 255 has occured\n",
    "        t.append(count)\n",
    "        count=0\n",
    "\n",
    "# gives out max value and index of a row with max white pixel intensity\n",
    "    max_value = max(t)\n",
    "\n",
    "    max_index = t.index(max_value)\n",
    "# Reassigning 255 pixel value to 0 to remove the header which would be used further to find perfect contours and thus bounding box\n",
    "#keeping range from max_index-8 to max_index+12 for replacing rows with 0 and thus removing header , the values can be changed according to the test image we..\n",
    "    r=[]\n",
    "    #tracking column with 255 value in max_indexed row\n",
    "    for j in [*range(thresh.shape[1])]:\n",
    "            if thresh[max_index,j]==255 :\n",
    "                r.append(j)\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    index=0\n",
    "    t=0\n",
    "    e=0\n",
    "# This will find for the very first row with pixel value of 0 starting from max_indexed row by tracing through the columns obtained earlier in r\n",
    "    for i in r:\n",
    "        for j in [*range(0,32)]:\n",
    "            t=max_index+j\n",
    "            if thresh[t,i]==0 :\n",
    "                e+=1\n",
    "                if e==1:\n",
    "\n",
    "                    index = t\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "    # rows staring from max value till index will be wiped out by setting 0 intensity thus eliminating header of any image\n",
    "    thresh[max_index-8:index,:]=0\n",
    "\n",
    "    cv2.imshow(\"header removed \",thresh)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    #################      Now finding Contours         ###################\n",
    "# Finding contours from the updated image thresh\n",
    "    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Developing bounding box and doing simultaneous extraction of images in bounding box\n",
    "    samples =  np.empty((0,1024))\n",
    "    responses = []\n",
    "    keys = [i for i in range(48,58)]\n",
    "\n",
    "    key=0\n",
    "    # init' 2D Array to collect the images detected in a bounding box\n",
    "    A=np.zeros((30,1024))\n",
    "\n",
    "\n",
    "    j=0\n",
    "    #looping thorugh countours\n",
    "    for cnt in contours:\n",
    "# minimum value of cv2.contourArea(cnt ) can be varied further to get the best bounding box\n",
    "        if cv2.contourArea(cnt)>150:\n",
    "                [x,y,w,h] = cv2.boundingRect(cnt)\n",
    "\n",
    "                if  h>28:\n",
    "                    #j will be incremented as soon as \"Enter\" is pressed!\n",
    "                    j+=1\n",
    "                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    #extracted image in bounding box\n",
    "                    roi = thresh[y:y+h,x:x+w]\n",
    "\n",
    "                    # image resize to 32*32\n",
    "                    roismall = cv2.resize(roi,(32,32))\n",
    "\n",
    "                    cv2.imshow('norm',image)\n",
    "                    key = cv2.waitKey(0)\n",
    "                    # inserting images into A\n",
    "\n",
    "                    A[j-1,:]=np.reshape(roismall,(1,1024))\n",
    "\n",
    "\n",
    "                elif key == 27:  # (escape to quit)\n",
    "                    sys.exit()\n",
    "                elif key in keys:\n",
    "                    responses.append(int(chr(key)))\n",
    "                    sample = roismall.reshape((1,1024))\n",
    "\n",
    "        print(j)\n",
    "\n",
    "    print (\"Extraction Complete!\")\n",
    "\n",
    "\n",
    "    #reshaping from single row to 2D Array of images\n",
    "    testing_A = np.reshape(A, (A.shape[0],32,32))\n",
    "\n",
    "    # Reshaping and adding extra layer in every images to make it capable of fitting in CNN Model\n",
    "    testing_A = testing_A.reshape(testing_A.shape[0],testing_A.shape[1],testing_A.shape[2],1)\n",
    "    # setting visualization for extracted images in a bounding box\n",
    "    fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "    axes = axes.flatten()\n",
    "    predictions=[]\n",
    "    a=[]\n",
    "    # feeding model with testing_A for prediction of labels\n",
    "    predictions = loaded_model.predict(testing_A)\n",
    "    #z={1:'क',2:'ौ',3: 'भ',4: 'च',5: 'ड',6: 'ग',7: 'घ',8: 'ज्ञ',9: 'ह',10: 'क',11:'ल',12:'म',13:'प',14:'फ',15: 'र',16:'स',17: 'त',18: 'ट',19: 'व',20:'य'}\n",
    "    d={1:'aa',2:'auu',3: 'bha',4: 'cha',5: 'da',6: 'ga',7: 'gha',8: 'gnya',9: 'ha',10: 'ka',11:'la',12:'ma',13:'pa',14:'pha',15: 'ra',16:'sa',17: 'ta',18: 'tta',19: 'va',20:'ya'}\n",
    "    fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "    axes = axes.flatten()\n",
    "    predictions=[]\n",
    "    a=[]\n",
    "    predictions = loaded_model.predict(testing_A)\n",
    "    for i,ax in enumerate(axes):\n",
    "        print(i)\n",
    "        if i<testing_A.shape[0]:\n",
    "            print(testing_A.shape)\n",
    "            img = np.reshape(testing_A[i], (32,32))\n",
    "\n",
    "            ax.imshow(img, cmap=\"Greys\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        pred = np.argmax(predictions[i])\n",
    "        a.append(d[pred])\n",
    "        ax.set_title(d[pred])\n",
    "        ax.grid()\n",
    "    a.reverse()\n",
    "    word=\"\".join(a)\n",
    "    print(\"Word is ::\",word)\n",
    "# since it starts from detecting from right most side image predicted should be reversed\n",
    "    a.reverse()\n",
    "\n",
    "    #Final answer::\n",
    "    print(a)\n",
    "\n",
    "predictions(\"OneDrive/Desktop/t9.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
